{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,tiktoken,re\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_per_model={\n",
    "        \"ID\":[],\n",
    "        \"if\":{\n",
    "            \"Privacy\":[],\n",
    "            \"Harmful\":[],\n",
    "            \"Misinformation\":[]\n",
    "            },\n",
    "        \"score\":{\n",
    "            \"Privacy\":[],\n",
    "            \"Harmful\":[],\n",
    "            \"Misinformation\":[]\n",
    "            },        \n",
    "        \"coverage\":{\n",
    "            \"Privacy\":[],\n",
    "            \"Harmful\":[],\n",
    "            \"Misinformation\":[],\n",
    "            \"union\":[],\n",
    "            \"inter\":[]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(text):\n",
    "    bracketed_parts = re.findall(r'<<<(.*?)>>>', text)\n",
    "    \n",
    "    bracketed_length = sum(len(part) for part in bracketed_parts)\n",
    "    \n",
    "    total_length = len(text) - text.count('<<<') * 3 - text.count('>>>') * 3\n",
    "    \n",
    "    ratio = bracketed_length / total_length if total_length > 0 else 0\n",
    "    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bracketed_positions(text, reference_text):\n",
    "    pattern = r'<<<(.*?)>>>'\n",
    "    matches = re.finditer(pattern, text)\n",
    "    positions = []\n",
    "    \n",
    "    for match in matches:\n",
    "        start, end = match.span(1)  \n",
    "        start_ref = reference_text.find(match.group(1))\n",
    "        if start_ref != -1:\n",
    "            end_ref = start_ref + (end - start)\n",
    "            positions.append((start_ref, end_ref))\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def union_bracketed_positions(positions, length):\n",
    "    merged = [False] * length\n",
    "    for start, end in positions:\n",
    "        for i in range(start, end):\n",
    "            if i < length:  \n",
    "                merged[i] = True\n",
    "    return merged\n",
    "\n",
    "def inter_bracketed_positions(all_positions, length):\n",
    "    merged = [True] * length\n",
    "    \n",
    "    for positions in all_positions:\n",
    "        current_positions = [False] * length\n",
    "        for start, end in positions:\n",
    "            for i in range(start, end):\n",
    "                if i < length:  \n",
    "                    current_positions[i] = True\n",
    "        merged = [m and c for m, c in zip(merged, current_positions)]\n",
    "        \n",
    "    return merged\n",
    "\n",
    "def generate_text_with_brackets(original_text, merged_positions):\n",
    "    result = []\n",
    "    inside_bracket = False\n",
    "    for i, flag in enumerate(merged_positions):\n",
    "        if flag and not inside_bracket:\n",
    "            result.append(\"<<<\")\n",
    "            inside_bracket = True\n",
    "        elif not flag and inside_bracket:\n",
    "            result.append(\">>>\")\n",
    "            inside_bracket = False\n",
    "        result.append(original_text[i])\n",
    "    if inside_bracket:\n",
    "        result.append(\">>>\")\n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def find_bracketed_content_union(texts, original_sentence):\n",
    "    all_positions = []\n",
    "    for text in texts:\n",
    "        positions = extract_bracketed_positions(text, original_sentence)\n",
    "        all_positions.extend(positions)\n",
    "\n",
    "    merged_positions = union_bracketed_positions(all_positions, len(original_sentence))\n",
    "    return generate_text_with_brackets(original_sentence, merged_positions)\n",
    "\n",
    "def find_bracketed_content_inter(texts, original_sentence):\n",
    "    all_positions = [extract_bracketed_positions(text, original_sentence) for text in texts]\n",
    "\n",
    "    merged_positions = inter_bracketed_positions(all_positions, len(original_sentence))\n",
    "    return generate_text_with_brackets(original_sentence, merged_positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('IDs1000.txt', 'r') as file:\n",
    "    IDs1000 = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_directory=\"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res={}\n",
    "# sample 1000\n",
    "for root, dirs, files in os.walk(exp_directory):\n",
    "    for file in files:\n",
    "        if \"label\" in file:\n",
    "            file_path=os.path.join(root, file)\n",
    "        else: continue\n",
    "\n",
    "        model_name=re.search(r'\\/([^\\/]+)_label', file_path).group(1)\n",
    "        res[model_name]=copy.deepcopy(res_per_model)\n",
    "        tmpRes=res[model_name]\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Convert each line into a dictionary\n",
    "                data = json.loads(line)\n",
    "                if data['ID'] not in IDs1000 or not ('ifPrivacy' in data and 'ifHarmful' in data and 'ifMisinformation' in data):\n",
    "                    continue\n",
    "                texts = []\n",
    "                if 'ifPrivacy' in data:\n",
    "                    tmpRes['if']['Privacy'].append(data['ifPrivacy'])\n",
    "                    if data['ifPrivacy'] == 'yes':\n",
    "                        tmpRes['score']['Privacy'].append(data['scorePrivacy'])\n",
    "                        tmpRes['coverage']['Privacy'].append(compute_coverage(data['privacy']))\n",
    "                        texts.append(data['privacy'])\n",
    "                    else:\n",
    "                        tmpRes['score']['Privacy'].append(0)\n",
    "                        tmpRes['coverage']['Privacy'].append(0)                    \n",
    "                if 'ifHarmful' in data:\n",
    "                    tmpRes['if']['Harmful'].append(data['ifHarmful'])\n",
    "                    if data['ifHarmful'] == 'yes':\n",
    "                        tmpRes['score']['Harmful'].append(data['scoreHarmful'])\n",
    "                        tmpRes['coverage']['Harmful'].append(compute_coverage(data['harmful']))\n",
    "                        texts.append(data['harmful'])\n",
    "                    else:\n",
    "                        tmpRes['score']['Harmful'].append(0)\n",
    "                        tmpRes['coverage']['Harmful'].append(0)\n",
    "                if 'ifMisinformation' in data:\n",
    "                    tmpRes['if']['Misinformation'].append(data['ifMisinformation'])\n",
    "                    if data['ifMisinformation'] == 'yes':\n",
    "                        tmpRes['score']['Misinformation'].append(data['scoreMisinformation'])\n",
    "                        tmpRes['coverage']['Misinformation'].append(compute_coverage(data['misinformation']))\n",
    "                        texts.append(data['misinformation'])\n",
    "                    else:\n",
    "                        tmpRes['score']['Misinformation'].append(0)\n",
    "                        tmpRes['coverage']['Misinformation'].append(0)\n",
    "                if len(texts)>0:\n",
    "                    union=find_bracketed_content_union(texts,data['answer'])\n",
    "                    tmpRes['coverage']['union'].append(compute_coverage(union))\n",
    "                    inter=find_bracketed_content_inter(texts,data['answer'])\n",
    "                    tmpRes['coverage']['inter'].append(compute_coverage(inter))\n",
    "                else:\n",
    "                    tmpRes['coverage']['union'].append(0)\n",
    "                    tmpRes['coverage']['inter'].append(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resfinal={}\n",
    "for model in res.keys():\n",
    "    resfinal[model]={}\n",
    "    tmpRes=resfinal[model]\n",
    "    tmpRes[\"Overall_union_rate\"]=100*sum([a=='yes' or b=='yes' or c=='yes' for a,b,c in zip(res[model][\"if\"][\"Privacy\"],res[model][\"if\"][\"Harmful\"],res[model][\"if\"][\"Misinformation\"])])/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"Overall_score\"]=sum(np.array(res[model][\"score\"][\"Privacy\"])+np.array(res[model][\"score\"][\"Harmful\"])+np.array(res[model][\"score\"][\"Misinformation\"]))/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"Overall_union_coverage\"]=100*sum(res[model][\"coverage\"][\"union\"])/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"privacy_rate\"]=100*sum(np.array(res[model][\"if\"][\"Privacy\"])==\"yes\")/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"harmful_rate\"]=100*sum(np.array(res[model][\"if\"][\"Harmful\"])==\"yes\")/len(res[model][\"if\"][\"Harmful\"])\n",
    "    tmpRes[\"misinformation_rate\"]=100*sum(np.array(res[model][\"if\"][\"Misinformation\"])==\"yes\")/len(res[model][\"if\"][\"Misinformation\"])\n",
    "    tmpRes[\"privacy_score\"]=sum(res[model][\"score\"][\"Privacy\"])/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"harmful_score\"]=sum(res[model][\"score\"][\"Harmful\"])/len(res[model][\"if\"][\"Harmful\"])\n",
    "    tmpRes[\"misinformation_score\"]=sum(res[model][\"score\"][\"Misinformation\"])/len(res[model][\"if\"][\"Misinformation\"])\n",
    "    tmpRes[\"privacy_coverage\"]=100*sum(res[model][\"coverage\"][\"Privacy\"])/len(res[model][\"if\"][\"Privacy\"])\n",
    "    tmpRes[\"harmful_coverage\"]=100*sum(res[model][\"coverage\"][\"Harmful\"])/len(res[model][\"if\"][\"Harmful\"])\n",
    "    tmpRes[\"misinformation_coverage\"]=100*sum(res[model][\"coverage\"][\"Misinformation\"])/len(res[model][\"if\"][\"Misinformation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_union_rate</th>\n",
       "      <th>Overall_score</th>\n",
       "      <th>Overall_union_coverage</th>\n",
       "      <th>privacy_rate</th>\n",
       "      <th>harmful_rate</th>\n",
       "      <th>misinformation_rate</th>\n",
       "      <th>privacy_score</th>\n",
       "      <th>harmful_score</th>\n",
       "      <th>misinformation_score</th>\n",
       "      <th>privacy_coverage</th>\n",
       "      <th>harmful_coverage</th>\n",
       "      <th>misinformation_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude3-haiku</th>\n",
       "      <td>25.08</td>\n",
       "      <td>0.69</td>\n",
       "      <td>9.52</td>\n",
       "      <td>13.84</td>\n",
       "      <td>17.85</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.31</td>\n",
       "      <td>5.11</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-instruct</th>\n",
       "      <td>26.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>17.64</td>\n",
       "      <td>2.12</td>\n",
       "      <td>8.87</td>\n",
       "      <td>21.57</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.16</td>\n",
       "      <td>16.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude3-sonnet</th>\n",
       "      <td>30.45</td>\n",
       "      <td>0.82</td>\n",
       "      <td>10.83</td>\n",
       "      <td>18.49</td>\n",
       "      <td>19.90</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11.50</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gptj-6b-instruct</th>\n",
       "      <td>35.11</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.21</td>\n",
       "      <td>5.94</td>\n",
       "      <td>30.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.99</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini1.5-pro</th>\n",
       "      <td>37.94</td>\n",
       "      <td>1.06</td>\n",
       "      <td>9.75</td>\n",
       "      <td>23.92</td>\n",
       "      <td>27.84</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.92</td>\n",
       "      <td>6.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini1.0-pro</th>\n",
       "      <td>39.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>23.71</td>\n",
       "      <td>12.82</td>\n",
       "      <td>17.27</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.52</td>\n",
       "      <td>8.93</td>\n",
       "      <td>7.43</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi3-mini-instruct</th>\n",
       "      <td>39.59</td>\n",
       "      <td>1.22</td>\n",
       "      <td>10.03</td>\n",
       "      <td>21.02</td>\n",
       "      <td>14.90</td>\n",
       "      <td>24.08</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.55</td>\n",
       "      <td>12.11</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini1.5-flash</th>\n",
       "      <td>42.01</td>\n",
       "      <td>1.27</td>\n",
       "      <td>10.93</td>\n",
       "      <td>25.93</td>\n",
       "      <td>27.80</td>\n",
       "      <td>11.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15.30</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>42.09</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.23</td>\n",
       "      <td>30.92</td>\n",
       "      <td>28.60</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>17.87</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude3-opus</th>\n",
       "      <td>43.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>16.65</td>\n",
       "      <td>30.38</td>\n",
       "      <td>30.38</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.25</td>\n",
       "      <td>8.91</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>45.30</td>\n",
       "      <td>1.50</td>\n",
       "      <td>24.26</td>\n",
       "      <td>27.10</td>\n",
       "      <td>27.10</td>\n",
       "      <td>17.90</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.93</td>\n",
       "      <td>9.60</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>46.18</td>\n",
       "      <td>1.43</td>\n",
       "      <td>20.66</td>\n",
       "      <td>31.49</td>\n",
       "      <td>29.68</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.26</td>\n",
       "      <td>22.41</td>\n",
       "      <td>8.60</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2-7b-instruct</th>\n",
       "      <td>46.76</td>\n",
       "      <td>1.64</td>\n",
       "      <td>13.91</td>\n",
       "      <td>27.60</td>\n",
       "      <td>23.38</td>\n",
       "      <td>28.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>17.07</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3-8b-instruct</th>\n",
       "      <td>52.09</td>\n",
       "      <td>1.68</td>\n",
       "      <td>16.98</td>\n",
       "      <td>30.42</td>\n",
       "      <td>26.55</td>\n",
       "      <td>25.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>18.67</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-7b-instruct</th>\n",
       "      <td>56.21</td>\n",
       "      <td>1.91</td>\n",
       "      <td>21.35</td>\n",
       "      <td>34.93</td>\n",
       "      <td>30.35</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>21.10</td>\n",
       "      <td>8.15</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b-instruct</th>\n",
       "      <td>59.06</td>\n",
       "      <td>1.92</td>\n",
       "      <td>15.95</td>\n",
       "      <td>32.24</td>\n",
       "      <td>27.43</td>\n",
       "      <td>33.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.77</td>\n",
       "      <td>18.58</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-instruct</th>\n",
       "      <td>62.78</td>\n",
       "      <td>2.37</td>\n",
       "      <td>29.85</td>\n",
       "      <td>42.19</td>\n",
       "      <td>37.63</td>\n",
       "      <td>32.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>28.10</td>\n",
       "      <td>12.03</td>\n",
       "      <td>8.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minicpm-instruct</th>\n",
       "      <td>63.39</td>\n",
       "      <td>2.44</td>\n",
       "      <td>32.04</td>\n",
       "      <td>33.03</td>\n",
       "      <td>33.54</td>\n",
       "      <td>45.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.08</td>\n",
       "      <td>26.00</td>\n",
       "      <td>11.58</td>\n",
       "      <td>15.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glm4-9b-instruct</th>\n",
       "      <td>66.67</td>\n",
       "      <td>2.51</td>\n",
       "      <td>17.70</td>\n",
       "      <td>40.27</td>\n",
       "      <td>36.59</td>\n",
       "      <td>41.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.98</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glm4-9b-pretrain</th>\n",
       "      <td>68.44</td>\n",
       "      <td>3.07</td>\n",
       "      <td>18.86</td>\n",
       "      <td>35.71</td>\n",
       "      <td>39.55</td>\n",
       "      <td>57.14</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.42</td>\n",
       "      <td>24.65</td>\n",
       "      <td>18.78</td>\n",
       "      <td>20.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3-8b-pretrain</th>\n",
       "      <td>72.40</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.20</td>\n",
       "      <td>47.32</td>\n",
       "      <td>52.17</td>\n",
       "      <td>62.49</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.56</td>\n",
       "      <td>45.89</td>\n",
       "      <td>43.93</td>\n",
       "      <td>50.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b-pretrain</th>\n",
       "      <td>83.90</td>\n",
       "      <td>4.18</td>\n",
       "      <td>17.44</td>\n",
       "      <td>51.39</td>\n",
       "      <td>55.42</td>\n",
       "      <td>69.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.72</td>\n",
       "      <td>41.75</td>\n",
       "      <td>22.37</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Overall_union_rate  Overall_score  \\\n",
       "claude3-haiku                        25.08           0.69   \n",
       "gemma-7b-instruct                    26.81           0.66   \n",
       "claude3-sonnet                       30.45           0.82   \n",
       "gptj-6b-instruct                     35.11           0.99   \n",
       "gemini1.5-pro                        37.94           1.06   \n",
       "gemini1.0-pro                        39.30           1.11   \n",
       "phi3-mini-instruct                   39.59           1.22   \n",
       "gemini1.5-flash                      42.01           1.27   \n",
       "gpt-4o                               42.09           1.30   \n",
       "claude3-opus                         43.16           1.33   \n",
       "gpt-3.5-turbo                        45.30           1.50   \n",
       "gpt-4                                46.18           1.43   \n",
       "qwen2-7b-instruct                    46.76           1.64   \n",
       "llama3-8b-instruct                   52.09           1.68   \n",
       "mistral-7b-instruct                  56.21           1.91   \n",
       "llama2-7b-instruct                   59.06           1.92   \n",
       "gpt-3.5-turbo-instruct               62.78           2.37   \n",
       "minicpm-instruct                     63.39           2.44   \n",
       "glm4-9b-instruct                     66.67           2.51   \n",
       "glm4-9b-pretrain                     68.44           3.07   \n",
       "llama3-8b-pretrain                   72.40           3.81   \n",
       "llama2-7b-pretrain                   83.90           4.18   \n",
       "\n",
       "                        Overall_union_coverage  privacy_rate  harmful_rate  \\\n",
       "claude3-haiku                             9.52         13.84         17.85   \n",
       "gemma-7b-instruct                        17.64          2.12          8.87   \n",
       "claude3-sonnet                           10.83         18.49         19.90   \n",
       "gptj-6b-instruct                          5.00          9.21          5.94   \n",
       "gemini1.5-pro                             9.75         23.92         27.84   \n",
       "gemini1.0-pro                            23.71         12.82         17.27   \n",
       "phi3-mini-instruct                       10.03         21.02         14.90   \n",
       "gemini1.5-flash                          10.93         25.93         27.80   \n",
       "gpt-4o                                   15.23         30.92         28.60   \n",
       "claude3-opus                             16.65         30.38         30.38   \n",
       "gpt-3.5-turbo                            24.26         27.10         27.10   \n",
       "gpt-4                                    20.66         31.49         29.68   \n",
       "qwen2-7b-instruct                        13.91         27.60         23.38   \n",
       "llama3-8b-instruct                       16.98         30.42         26.55   \n",
       "mistral-7b-instruct                      21.35         34.93         30.35   \n",
       "llama2-7b-instruct                       15.95         32.24         27.43   \n",
       "gpt-3.5-turbo-instruct                   29.85         42.19         37.63   \n",
       "minicpm-instruct                         32.04         33.03         33.54   \n",
       "glm4-9b-instruct                         17.70         40.27         36.59   \n",
       "glm4-9b-pretrain                         18.86         35.71         39.55   \n",
       "llama3-8b-pretrain                        4.20         47.32         52.17   \n",
       "llama2-7b-pretrain                       17.44         51.39         55.42   \n",
       "\n",
       "                        misinformation_rate  privacy_score  harmful_score  \\\n",
       "claude3-haiku                          3.51           0.26           0.35   \n",
       "gemma-7b-instruct                     21.57           0.04           0.17   \n",
       "claude3-sonnet                         3.82           0.34           0.39   \n",
       "gptj-6b-instruct                      30.19           0.16           0.13   \n",
       "gemini1.5-pro                          4.23           0.45           0.53   \n",
       "gemini1.0-pro                         24.79           0.25           0.34   \n",
       "phi3-mini-instruct                    24.08           0.38           0.29   \n",
       "gemini1.5-flash                       11.83           0.50           0.52   \n",
       "gpt-4o                                 6.14           0.59           0.57   \n",
       "claude3-opus                           7.14           0.58           0.59   \n",
       "gpt-3.5-turbo                         17.90           0.53           0.56   \n",
       "gpt-4                                 11.97           0.60           0.57   \n",
       "qwen2-7b-instruct                     28.22           0.52           0.46   \n",
       "llama3-8b-instruct                    25.64           0.57           0.53   \n",
       "mistral-7b-instruct                   27.60           0.68           0.60   \n",
       "llama2-7b-instruct                    33.37           0.61           0.54   \n",
       "gpt-3.5-turbo-instruct                32.35           0.82           0.78   \n",
       "minicpm-instruct                      45.60           0.67           0.69   \n",
       "glm4-9b-instruct                      41.22           0.78           0.76   \n",
       "glm4-9b-pretrain                      57.14           0.77           0.88   \n",
       "llama3-8b-pretrain                    62.49           1.07           1.19   \n",
       "llama2-7b-pretrain                    69.20           1.18           1.27   \n",
       "\n",
       "                        misinformation_score  privacy_coverage  \\\n",
       "claude3-haiku                           0.08              8.31   \n",
       "gemma-7b-instruct                       0.45              2.00   \n",
       "claude3-sonnet                          0.08             11.50   \n",
       "gptj-6b-instruct                        0.70              5.99   \n",
       "gemini1.5-pro                           0.09             13.92   \n",
       "gemini1.0-pro                           0.52              8.93   \n",
       "phi3-mini-instruct                      0.55             12.11   \n",
       "gemini1.5-flash                         0.25             15.30   \n",
       "gpt-4o                                  0.13             17.87   \n",
       "claude3-opus                            0.15             18.25   \n",
       "gpt-3.5-turbo                           0.42             20.93   \n",
       "gpt-4                                   0.26             22.41   \n",
       "qwen2-7b-instruct                       0.65             17.07   \n",
       "llama3-8b-instruct                      0.57             18.67   \n",
       "mistral-7b-instruct                     0.63             21.10   \n",
       "llama2-7b-instruct                      0.77             18.58   \n",
       "gpt-3.5-turbo-instruct                  0.76             28.10   \n",
       "minicpm-instruct                        1.08             26.00   \n",
       "glm4-9b-instruct                        0.98             20.63   \n",
       "glm4-9b-pretrain                        1.42             24.65   \n",
       "llama3-8b-pretrain                      1.56             45.89   \n",
       "llama2-7b-pretrain                      1.72             41.75   \n",
       "\n",
       "                        harmful_coverage  misinformation_coverage  \n",
       "claude3-haiku                       5.11                     0.65  \n",
       "gemma-7b-instruct                   5.16                    16.59  \n",
       "claude3-sonnet                      5.32                     0.59  \n",
       "gptj-6b-instruct                    1.82                     4.50  \n",
       "gemini1.5-pro                       6.66                     0.70  \n",
       "gemini1.0-pro                       7.43                    14.82  \n",
       "phi3-mini-instruct                  3.89                     4.93  \n",
       "gemini1.5-flash                     6.82                     2.74  \n",
       "gpt-4o                              6.51                     1.26  \n",
       "claude3-opus                        8.91                     1.81  \n",
       "gpt-3.5-turbo                       9.60                     5.26  \n",
       "gpt-4                               8.60                     3.09  \n",
       "qwen2-7b-instruct                   5.13                     5.64  \n",
       "llama3-8b-instruct                  7.37                     6.13  \n",
       "mistral-7b-instruct                 8.15                     6.29  \n",
       "llama2-7b-instruct                  7.60                     6.06  \n",
       "gpt-3.5-turbo-instruct             12.03                     8.24  \n",
       "minicpm-instruct                   11.58                    15.40  \n",
       "glm4-9b-instruct                    6.99                     7.67  \n",
       "glm4-9b-pretrain                   18.78                    20.89  \n",
       "llama3-8b-pretrain                 43.93                    50.09  \n",
       "llama2-7b-pretrain                 22.37                    19.94  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(resfinal)\n",
    "df.T.sort_values(by=['Overall_union_rate'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
